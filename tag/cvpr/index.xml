<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CVPR | Xin Ma</title>
    <link>https://maxin-cn.github.io/tag/cvpr/</link>
      <atom:link href="https://maxin-cn.github.io/tag/cvpr/index.xml" rel="self" type="application/rss+xml" />
    <description>CVPR</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Thu, 27 Feb 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://maxin-cn.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>CVPR</title>
      <link>https://maxin-cn.github.io/tag/cvpr/</link>
    </image>
    
    <item>
      <title>ðŸŽ‰ one paper Cinemo was accpeted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
      <link>https://maxin-cn.github.io/post/cinemo-cvpr/</link>
      <pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://maxin-cn.github.io/post/cinemo-cvpr/</guid>
      <description>&lt;p&gt;one paper &lt;a href=&#34;../../publication/conference-paper/cvpr_ma_2025/&#34;&gt;Cinemo&lt;/a&gt; was accpeted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Diffusion models have achieved significant progress in the task of image animation due to their powerful generative capabilities. However, preserving appearance consistency to the static input image, and avoiding abrupt motion change in the generated animation, remains challenging.
In this paper, we introduce Cinemo, a novel image animation approach that aims at achieving better appearance consistency and motion smoothness. The core of Cinemo is to focus on learning the distribution of motion residuals, rather than directly predicting frames as in existing diffusion models.
During the inference, we further mitigate the sudden motion changes in the generated video by introducing a novel DCT-based noise refinement strategy.
To counteract the over-smoothing of motion, we introduce a dynamics degree control design for better control of the magnitude of motion.
Altogether, these strategies enable Cinemo to produce highly consistent, smooth, and motion-controllable results. Extensive experiments compared with several state-of-the-art methods demonstrate the effectiveness and superiority of our proposed approach.
In the end, we also demonstrate how our model can be applied for motion transfer or video editing of any given video. The project page is available at &lt;a href=&#34;https://maxin-cn.github.io/cinemo_project/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://maxin-cn.github.io/cinemo_project/&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;
&lt;p&gt;Download and set up the repo:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
git clone https://github.com/maxin-cn/Cinemo
cd Cinemo
conda env create -f environment.yml
conda activate cinemo
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;h2 id=&#34;animation&#34;&gt;Animation&lt;/h2&gt;
&lt;p&gt;You can sample from our pre-trained Cinemo models. Weights for our pre-trained Cinemo model can be found &lt;a href=&#34;https://huggingface.co/maxin-cn/Cinemo/tree/main&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. The script has various arguments for adjusting sampling steps, changing the classifier-free guidance scale, etc:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
bash pipelines/animation.sh
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Related model weights will be downloaded automatically, and the following results can be found &lt;a href=&#34;https://github.com/maxin-cn/Cinemo/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Consistent and Controllable Image Animation with Motion Diffusion Models</title>
      <link>https://maxin-cn.github.io/publication/conference-paper/cvpr_ma_2025/</link>
      <pubDate>Mon, 22 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://maxin-cn.github.io/publication/conference-paper/cvpr_ma_2025/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;!-- 

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;


Add the publication&#39;s **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). --&gt;</description>
    </item>
    
    <item>
      <title>Compressing Models with Few Samples: Mimicking then Replacing</title>
      <link>https://maxin-cn.github.io/publication/conference-paper/cvpr_2022/</link>
      <pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate>
      <guid>https://maxin-cn.github.io/publication/conference-paper/cvpr_2022/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;!-- 

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
  </channel>
</rss>
